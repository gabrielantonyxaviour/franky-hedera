# Franky
Monetize your old devices by powering efficient AI agents.

![image](https://github.com/user-attachments/assets/e903a068-3bea-4c29-9f9c-049ce820ff92)

## Description

Not sure what to do with your OLD mobile? Franky helps you to run Local LLM Inference right in your device and **MONETIZE** your compute with **$FRANKY** tokens. Device Owners could contribute their old devices to run LLMs locally and host AI agents on top of them to earn **$FRANKY** tokens. Agent creators could choose a device of their choice to build their Agent from scratch with it's very own custom characteristics and generate an API key to interact with them. Agents could also be made publicly available by the Agent Creator for others to use them and in-turn earn **$FRANKY** tokens. Agent developers could build plugins in our AI Agent Framework to build custom functionalities. Each Agent has their VERY OWN custom subdomain which makes it readable and convenient to interact with.
## How it's made

The application is built on **Base** and uses **Metal** for token transfers. For real-time data management, we integrated **Nodit’s Web3 Data API**, **Elastic Nodes**, and **Streams**. These technologies allow for the efficient indexing of multi-chain data—such as balances and transaction history—ensuring that users can access this information instantly and without delay. The use of  **Web3 data API** and **Streams** ensure that data updates happen in real-time, providing a highly dynamic and responsive user experience.

**Metal** was useful for us to create the $FRANKY tokens and simplified the ENTIRE transaction flow between Device Providers, Agent Creators and the Platform Owners. An LLM runs locally in the mobile phone and the Agent Framework implemented for Franky Agents is a Fork of the SillyTavern Framework.

Every single agent upon creation has their own ENS name. We do this by minting the DNS Subdomain on **ENS**, thereby making it seamless for users to interact with the agent of their choice.

## Sponsors

### Metal

The tokenomics in the Franky Agents ecosystem is managed by the $FRANKY tokens. These tokens were created from **Metal** and the liquidity pool comprises of $FRANKY and USDC. Metal accomodates the API Exhaustion from the User side by deducting $FRANKY tokens directly from their wallet whenever a request is made to the Agent's ENS endpoint and distributes the necessary funds between the Device Owners and the Platform Owners.

The same happens when a new user interacts with an existing agent displayed in the marketplace. The necessary $FRANKY tokens are distributed between the Agent Creator, Device Owner and the Platform Owners. This results in real-time transfer of $FRANKY tokens in a seamless fashion.

### Nodit

We have built a fully functional application on Base Mainnet which facilitates to repurpose OLD mobile phones and EARN **$FRANKY** tokens by running local LLM inference and host AI agents in them, providing Affordable Agent compute to everyone

We use Nodit’s Elastic Node, Web3 Data API, Websockets, and Streams to index and display the various data related to Agent Details, Device Information and User Data. This includes list of Agents and Mobile Devices, real-time balances, Wallet Specific Information, and Event Listeners—all rendered with minimal latency and a smooth, clean UX.

Nodit’s developer-first tooling makes it easy to provide a fast, reliable, and highly responsive experience without having to manage complex indexing infrastructure. The result is a lightweight, data-rich Application that brings a **COMPLETELY** decentralized solution.

Thanks to Nodit, users can list their devices, host their agents quickly and arrive at insights WITHOUT any hassle.

### ENS

We have used ENS to mint subdomains for EVERY SINGLE Agent created in our application and also include ALL the metadata about the agent like, character data, profile picture, agent address etc. We have also made the subdomains as the means to communicate with the created Agent

### Metal Line of Code

https://github.com/gabrielantonyxaviour/bombardiro-crocodilo/blob/main/README.md#world-line-of-code

### Nodit Line of Code

https://github.com/gabrielantonyxaviour/bombardiro-crocodilo/blob/main/README.md#nodit-line-of-code

### ENS Line of Code

https://github.com/gabrielantonyxaviour/bombardiro-crocodilo/blob/main/README.md#hyperlane-line-of-code

### Metal Feedback

Super easy to use and integrate. I have added my feedback here.

https://github.com/gabrielantonyxaviour/bombardiro-crocodilo/blob/main/README.md#world-feedback

### Nodit Feedback

Super easy to use and integrate. Webhooks and Websockets possess a latency which could be reduced
Under Websockets, LOGs could facilitate listening to various topics in multiple events instead of looking for a bunch of topics under the same event in an address

https://github.com/gabrielantonyxaviour/bombardiro-crocodilo/blob/main/README.md#nodit-feedback

### ENS Feedback

Super easy to use and integrate. I have added my feedback here.

https://github.com/gabrielantonyxaviour/bombardiro-crocodilo/blob/main/README.md#hyperlane-feedback

This is my 3rd year aniversary building on Hyperlane. It was the first sponsor I built on for an ETHGlobal Hackathon. Super glad to keep build new things on Hyperlane.
